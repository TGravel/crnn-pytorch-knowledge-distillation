{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed515546",
   "metadata": {},
   "source": [
    "# Dataset preparation\n",
    "\n",
    "This is a small python script to adjust CocoTextv2 data to the style and lexicon of MJSynth. The test split of the dataset will be separated into test and validation split. Note that words not available in the lexicon will be excluded by the preparation! The script creates a cutout of the annotated bbox and saves it in a folder to prepare the data for recognition. This can take some time to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bd8bb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:02.069921\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import coco_text\n",
    "import regex as re\n",
    "import random\n",
    "random.seed(42)\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "ct = coco_text.COCO_Text('cocotext.v2.json') # Notice that this file is required: https://bgshih.github.io/cocotext/#h2-download\n",
    "ct.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dca536e",
   "metadata": {},
   "source": [
    "## Set user paths: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c18ddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lexicon\n",
    "path_to_lexicon = r\"C:\\Users\\tom\\Documents\\JKU\\PracticalWorkOCR\\PytorchCRNN\\crnn-pytorch\\data\\lexicon.txt\"\n",
    "\n",
    "# Dataset\n",
    "dataset_directory = r'C://Users//tom//Documents//JKU//PracticalWorkOCR//DATASET12GB//'\n",
    "dataType = 'train2014'\n",
    "# Where to store the cropped data:\n",
    "savepath = r'C://Users//tom//Documents//JKU//PracticalWorkOCR//PytorchCRNN//crnn-pytorch//data'\n",
    "\n",
    "# Save annotation file to:\n",
    "path_annotation_val = r'C://Users//tom//Documents//JKU//PracticalWorkOCR//PytorchCRNN//crnn-pytorch//data//coco_annotations_val.txt'\n",
    "path_annotation_test = r'C://Users//tom//Documents//JKU//PracticalWorkOCR//PytorchCRNN//crnn-pytorch//data//coco_annotations_test.txt'\n",
    "path_annotation_train = r'C://Users//tom//Documents//JKU//PracticalWorkOCR//PytorchCRNN//crnn-pytorch//data//coco_annotations_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bb5906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_to_lexicon, \"r\") as f:\n",
    "    f = f.read()\n",
    "    lexicon = f.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95aa8d0e",
   "metadata": {},
   "source": [
    "## Val/Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b401067d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val: 4727\n",
      "Test: 4642\n"
     ]
    }
   ],
   "source": [
    "with open(path_annotation_val, 'w') as af:\n",
    "    af.write(\"\")\n",
    "with open(path_annotation_test, 'w') as af:\n",
    "    af.write(\"\")\n",
    "imgIds = ct.getImgIds(imgIds=ct.val, catIds=[('legibility','legible')])\n",
    "imgcount1 = 0\n",
    "imgcount2 = 0\n",
    "for i in imgIds:\n",
    "    annIds = ct.getAnnIds(imgIds=i)\n",
    "    anns = ct.loadAnns(annIds)\n",
    "    for j in anns:\n",
    "        if j['legibility'] == 'legible' and j['utf8_string']:\n",
    "            j_string = re.sub('[^A-Za-z0-9]+', '', j['utf8_string'].lower())\n",
    "            if j_string == \"\":\n",
    "                j_string = \"specialtoken\"\n",
    "            try:\n",
    "                found_at = lexicon.index(j_string)\n",
    "                if bool(random.getrandbits(1)):\n",
    "                    with open(path_annotation_val, 'a') as af:\n",
    "                        af.write(f'./cropped/{str(i)}_{str(j_string)}_{str(found_at)}.jpg {str(found_at)}\\n')\n",
    "                        imgcount1 += 1\n",
    "                else:\n",
    "                    with open(path_annotation_test, 'a') as af:\n",
    "                        af.write(f'./cropped/{str(i)}_{str(j_string)}_{str(found_at)}.jpg {str(found_at)}\\n')\n",
    "                        imgcount2 += 1\n",
    "                img = ct.loadImgs(i)[0]\n",
    "                rimg = Image.open(os.path.join(dataset_directory, 'images/%s/%s'%(dataType,img['file_name'])))\n",
    "                if True: #mask images\n",
    "                    mask = Image.new(\"L\", rimg.size, 0)\n",
    "                    im2 = Image.new(mode=\"RGB\", size=rimg.size)\n",
    "                    draw = ImageDraw.Draw(mask)\n",
    "                    draw.polygon(j['mask'], fill=255)\n",
    "                    im = Image.composite(rimg, im2, mask)\n",
    "                im_crop = im.crop((j['bbox'][0], j['bbox'][1], j['bbox'][0] + j['bbox'][2], j['bbox'][1] + j['bbox'][3]))\n",
    "                im_crop.save(f'{savepath}//cropped//{str(i)}_{str(j_string)}_{str(found_at)}.jpg')\n",
    "                \n",
    "            except ValueError:\n",
    "                continue\n",
    "print(f\"Val: {imgcount1}\")\n",
    "print(f\"Test: {imgcount2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e27d0ed",
   "metadata": {},
   "source": [
    "## Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4033cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 42313\n"
     ]
    }
   ],
   "source": [
    "with open(path_annotation_train, 'w') as af:\n",
    "    af.write(\"\")\n",
    "imgIds = ct.getImgIds(imgIds=ct.train, catIds=[('legibility','legible')])\n",
    "imgcount1 = 0\n",
    "for i in imgIds:\n",
    "    annIds = ct.getAnnIds(imgIds=i)\n",
    "    anns = ct.loadAnns(annIds)\n",
    "    for j in anns:\n",
    "        if j['legibility'] == 'legible' and j['utf8_string']:\n",
    "            j_string = re.sub('[^A-Za-z0-9]+', '', j['utf8_string'].lower())\n",
    "            if j_string == \"\":\n",
    "                j_string = \"specialtoken\"\n",
    "            try:\n",
    "                found_at = lexicon.index(j_string)\n",
    "                with open(path_annotation_train, 'a') as af:\n",
    "                    af.write(f'./cropped/{str(i)}_{str(j_string)}_{str(found_at)}.jpg {str(found_at)}\\n')\n",
    "                    imgcount1 += 1\n",
    "                img = ct.loadImgs(i)[0]\n",
    "                rimg = Image.open(os.path.join(dataset_directory, 'images/%s/%s'%(dataType,img['file_name'])))\n",
    "                if True: #mask images\n",
    "                    mask = Image.new(\"L\", rimg.size, 0)\n",
    "                    im2 = Image.new(mode=\"RGB\", size=rimg.size)\n",
    "                    draw = ImageDraw.Draw(mask)\n",
    "                    draw.polygon(j['mask'], fill=255)\n",
    "                    im = Image.composite(rimg, im2, mask)\n",
    "                im_crop = im.crop((j['bbox'][0], j['bbox'][1], j['bbox'][0] + j['bbox'][2], j['bbox'][1] + j['bbox'][3]))\n",
    "                im_crop.save(f'{savepath}//cropped//{str(i)}_{str(j_string)}_{str(found_at)}.jpg')\n",
    "            except ValueError:\n",
    "                continue\n",
    "print(f\"Train: {imgcount1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ec1eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
