{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05fc85ef",
   "metadata": {},
   "source": [
    "# Dataset preparation - ICDAR2013\n",
    "\n",
    "This is a small python script to adjust ICDAR2013 annotation files to the style and lexicon of MJSynth. Note that words not available in the lexicon will be excluded by the preparation! The script stores file references in a newly created annotation file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bd8bb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import coco_text\n",
    "import regex as re\n",
    "import random\n",
    "import json\n",
    "random.seed(42)\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce6a493",
   "metadata": {},
   "source": [
    "## Set user paths: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cf04194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lexicon\n",
    "path_to_lexicon = r\"C:\\Users\\tom\\Documents\\JKU\\PracticalWorkOCR\\PytorchCRNN\\crnn-pytorch\\data\\lexicon.txt\"\n",
    "\n",
    "# Dataset (Annotation file must be in same location as dataset)\n",
    "annotation = r'C:\\Users\\tom\\Documents\\JKU\\PracticalWorkOCR\\DATASET12GB\\icdar2013\\icdar_2013_train_labels.txt'\n",
    "annotation2 = r'C:\\Users\\tom\\Documents\\JKU\\PracticalWorkOCR\\DATASET12GB\\icdar2013\\icdar_2013_test_labels.txt'\n",
    "\n",
    "# Save created annotation file to:\n",
    "path_annotation_train = r'C://Users//tom//Documents//JKU//PracticalWorkOCR//DATASET12GB//icdar2013//icdar2013_annotations_train.txt'\n",
    "path_annotation_test = r'C://Users//tom//Documents//JKU//PracticalWorkOCR//DATASET12GB//icdar2013//icdar2013_annotations_test.txt'\n",
    "\n",
    "# Note that train, val, test splits for this dataset are randomly created by src\\dataset.py and not here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bb5906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_to_lexicon, \"r\") as f:\n",
    "    f = f.read()\n",
    "    lexicon = f.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b2cea0",
   "metadata": {},
   "source": [
    "## Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dd09ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 684 images to annotation file.\n"
     ]
    }
   ],
   "source": [
    "with open(path_annotation_train, 'w') as af:\n",
    "    af.write(\"\")\n",
    "\n",
    "imgcount = 0\n",
    "with open(annotation, 'r') as f:\n",
    "    text = f.read()\n",
    "for i in text.split(\"\\n\"):\n",
    "    info = i.split(\" \")\n",
    "    if len(info) != 2:\n",
    "        continue\n",
    "    i_string = re.sub('[^A-Za-z0-9]+', '', info[1].lower())\n",
    "    if i_string == \"\":\n",
    "        continue\n",
    "    try:\n",
    "        found_at = lexicon.index(i_string)\n",
    "        with open(path_annotation_train, 'a') as af:\n",
    "            af.write(f'./{info[0]} {str(found_at)}\\n')\n",
    "            imgcount += 1\n",
    "    except ValueError:\n",
    "        continue\n",
    "print(f\"Added {imgcount} images to annotation file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f657e71",
   "metadata": {},
   "source": [
    "## Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35ac41e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 1015 images to annotation file\n"
     ]
    }
   ],
   "source": [
    "with open(path_annotation_test, 'w') as af:\n",
    "    af.write(\"\")\n",
    "\n",
    "imgcount = 0\n",
    "with open(annotation2, 'r') as f:\n",
    "    text = f.read()\n",
    "for i in text.split(\"\\n\"):\n",
    "    info = i.split(\" \")\n",
    "    if len(info) != 2:\n",
    "        continue\n",
    "    i_string = re.sub('[^A-Za-z0-9]+', '', info[1].lower())\n",
    "    if i_string == \"\":\n",
    "        continue\n",
    "    try:\n",
    "        found_at = lexicon.index(i_string)\n",
    "        with open(path_annotation_test, 'a') as af:\n",
    "            af.write(f'./{info[0]} {str(found_at)}\\n')\n",
    "            imgcount += 1\n",
    "    except ValueError:\n",
    "        continue\n",
    "print(f\"Added {imgcount} images to annotation file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6581188",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
