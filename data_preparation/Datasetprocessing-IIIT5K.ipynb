{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b464d08",
   "metadata": {},
   "source": [
    "# Dataset preparation - IIIT5K\n",
    "\n",
    "This is a small python script to adjust IIIT5K annotation files to the style and lexicon of MJSynth. Note that words not available in the lexicon will be excluded by the preparation! The script stores file references in a newly created annotation file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bd8bb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import coco_text\n",
    "import regex as re\n",
    "import random\n",
    "import json\n",
    "random.seed(42)\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7b60f9",
   "metadata": {},
   "source": [
    "## Set user paths: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14c55bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lexicon\n",
    "path_to_lexicon = r\"C:\\Users\\tom\\Documents\\JKU\\PracticalWorkOCR\\PytorchCRNN\\crnn-pytorch\\data\\lexicon.txt\"\n",
    "\n",
    "# Dataset (Annotation file must be in same location as dataset)\n",
    "annotation = r'C:\\Users\\tom\\Documents\\JKU\\PracticalWorkOCR\\DATASET12GB\\IIIT5K\\IIIT5K_train_label.txt'\n",
    "annotation2 = r'C:\\Users\\tom\\Documents\\JKU\\PracticalWorkOCR\\DATASET12GB\\IIIT5K\\IIIT5K_test_label.txt'\n",
    "\n",
    "# Save created annotation file to:\n",
    "path_annotation_train = r'C://Users//tom//Documents//JKU//PracticalWorkOCR//DATASET12GB//IIIT5K//iiit5k_annotations_train.txt'\n",
    "path_annotation_test = r'C://Users//tom//Documents//JKU//PracticalWorkOCR//DATASET12GB//IIIT5K//iiit5k_annotations_test.txt'\n",
    "\n",
    "\n",
    "# Note that train, val, test splits for this dataset are randomly created by src\\dataset.py and not here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6acc9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_to_lexicon, \"r\") as f:\n",
    "    f = f.read()\n",
    "    lexicon = f.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62768c7",
   "metadata": {},
   "source": [
    "## Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dd09ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 1591 images to annotation file.\n"
     ]
    }
   ],
   "source": [
    "with open(path_annotation_train, 'w') as af:\n",
    "    af.write(\"\")\n",
    "\n",
    "imgcount = 0\n",
    "with open(annotation, 'r') as f:\n",
    "    text = f.read()\n",
    "for i in text.split(\"\\n\"):\n",
    "    info = i.split(\" \")\n",
    "    if len(info) != 2:\n",
    "        #print(\"Invalid annotation\")\n",
    "        continue\n",
    "    i_string = re.sub('[^A-Za-z0-9]+', '', info[1].lower())\n",
    "    if i_string == \"\":\n",
    "        #print(\"Empty annotation\")\n",
    "        continue\n",
    "    try:\n",
    "        found_at = lexicon.index(i_string)\n",
    "        with open(path_annotation_train, 'a') as af:\n",
    "            af.write(f'{os.path.join(\"train\", info[0])} {str(found_at)}\\n')\n",
    "            imgcount += 1\n",
    "    except ValueError:\n",
    "        #print(i, \" not found in lexicon\")\n",
    "        continue\n",
    "print(f\"Added {imgcount} images to annotation file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923e151f",
   "metadata": {},
   "source": [
    "## Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b401067d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 2415 images to annotation file.\n"
     ]
    }
   ],
   "source": [
    "with open(path_annotation_test, 'w') as af:\n",
    "    af.write(\"\")\n",
    "\n",
    "imgcount = 0\n",
    "invcount = 0\n",
    "with open(annotation2, 'r') as f:\n",
    "    text = f.read()\n",
    "for i in text.split(\"\\n\"):\n",
    "    info = i.split(\" \")\n",
    "    if len(info) != 2:\n",
    "        #print(\"Invalid annotation\")\n",
    "        invcount += 1\n",
    "        continue\n",
    "    i_string = re.sub('[^A-Za-z0-9]+', '', info[1].lower())\n",
    "    if i_string == \"\":\n",
    "        #print(\"Empty annotation\")\n",
    "        continue\n",
    "    try:\n",
    "        found_at = lexicon.index(i_string)\n",
    "        with open(path_annotation_test, 'a') as af:\n",
    "            af.write(f'{os.path.join(\"test\", info[0])} {str(found_at)}\\n')\n",
    "            imgcount += 1\n",
    "    except ValueError:\n",
    "        #print(i, \" not found in lexicon\")\n",
    "        invcount += 1\n",
    "        continue\n",
    "print(f\"Added {imgcount} images to annotation file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5051c78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
